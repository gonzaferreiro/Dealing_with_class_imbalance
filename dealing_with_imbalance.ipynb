{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I you have had the chance of working around classification problems, then is probable you have faced a problem of imbalanced classes. This occurs in datasets with a disproportionate ratio of observations. In other words, in a binary classification problem, youâ€™d have a lot of elements of a class and very few from another. But this could also happen in a multi-classification problem when we the vast majority of the observations are clustered in one category or we have one category that's highly under-represented in comparison with the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed_acidity</th>\n",
       "      <th>volatile_acidity</th>\n",
       "      <th>citric_acid</th>\n",
       "      <th>residual_sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free_sulfur_dioxide</th>\n",
       "      <th>total_sulfur_dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>red_wine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  red_wine  \n",
       "0      9.4        5         1  \n",
       "1      9.8        5         1  \n",
       "2      9.8        5         1  \n",
       "3      9.8        6         1  \n",
       "4      9.4        5         1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wine_data/winequality_merged.csv')\n",
    "df.columns = [col.replace(' ','_') for col in df.columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4898\n",
       "1    1599\n",
       "Name: red_wine, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.red_wine.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to predict good or bad quality (below 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.pop('quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    2836\n",
       "5    2138\n",
       "7    1079\n",
       "4     216\n",
       "8     193\n",
       "3      30\n",
       "9       5\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (y > 4)*1\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.962136\n",
       "0    0.037864\n",
       "Name: quality, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gonzaloferreiro/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/gonzaloferreiro/anaconda3/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/gonzaloferreiro/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                        test_size=0.2, stratify=y, random_state=1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=X.columns, index=y_train.index)\n",
    "X_test = pd.DataFrame(X_test,  columns=X.columns, index=y_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitter(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Takes a model, training and test sets as inputs and evaluated the model on both \n",
    "    reporting scores, confusion matrix and classification report.\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model.score(X_train, y_train))\n",
    "    print(cross_val_score(model, X_train, y_train, cv=5).mean())\n",
    "    print(model.score(X_test, y_test))\n",
    "    print()\n",
    "    print(confusion_matrix(y_train, model.predict(X_train)))\n",
    "    print()\n",
    "    print(classification_report(y_train, model.predict(X_train)))\n",
    "    print()\n",
    "    print(confusion_matrix(y_test, model.predict(X_test)))\n",
    "    print()\n",
    "    print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9630556090051953\n",
      "0.9615384615384616\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9630556090051953\n",
      "0.9628635152143333\n",
      "0.9615384615384616\n",
      "\n",
      "[[   9  188]\n",
      " [   4 4996]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.05      0.09       197\n",
      "           1       0.96      1.00      0.98      5000\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5197\n",
      "   macro avg       0.83      0.52      0.53      5197\n",
      "weighted avg       0.95      0.96      0.95      5197\n",
      "\n",
      "\n",
      "[[   0   49]\n",
      " [   1 1250]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        49\n",
      "           1       0.96      1.00      0.98      1251\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1300\n",
      "   macro avg       0.48      0.50      0.49      1300\n",
      "weighted avg       0.93      0.96      0.94      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fitter(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can put that model into a neat pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9630556090051953\n",
      "0.9628635152143333\n",
      "0.9615384615384616\n",
      "\n",
      "[[   9  188]\n",
      " [   4 4996]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.05      0.09       197\n",
      "           1       0.96      1.00      0.98      5000\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      5197\n",
      "   macro avg       0.83      0.52      0.53      5197\n",
      "weighted avg       0.95      0.96      0.95      5197\n",
      "\n",
      "\n",
      "[[   0   49]\n",
      " [   1 1250]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        49\n",
      "           1       0.96      1.00      0.98      1251\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1300\n",
      "   macro avg       0.48      0.50      0.49      1300\n",
      "weighted avg       0.93      0.96      0.94      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(StandardScaler(),model)\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "fitter(pipe, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance the class weights\n",
    "\n",
    "One way of treating class imbalances when using logistic regression is to use `class_weight='balanced'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7523571291129498\n",
      "0.7490886207151847\n",
      "0.7676923076923077\n",
      "\n",
      "[[ 136   61]\n",
      " [1226 3774]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.69      0.17       197\n",
      "           1       0.98      0.75      0.85      5000\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5197\n",
      "   macro avg       0.54      0.72      0.51      5197\n",
      "weighted avg       0.95      0.75      0.83      5197\n",
      "\n",
      "\n",
      "[[ 30  19]\n",
      " [283 968]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.61      0.17        49\n",
      "           1       0.98      0.77      0.87      1251\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1300\n",
      "   macro avg       0.54      0.69      0.52      1300\n",
      "weighted avg       0.95      0.77      0.84      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_balanced = LogisticRegression(solver='lbfgs', \n",
    "                                    multi_class='ovr', \n",
    "                                    max_iter=1000,\n",
    "                                    class_weight='balanced')\n",
    "\n",
    "\n",
    "fitter(model_balanced, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling using [imbalanced learn](http://contrib.scikit-learn.org/imbalanced-learn/stable/index.html)\n",
    "\n",
    "Alternatively we can use resampling methods such as undersampling and oversampling or even generate new samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling\n",
    "\n",
    "We create class balance by selecting a random subset of the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    197\n",
       "0    197\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler = RandomUnderSampler(random_state=1)\n",
    "X_resampled, y_resampled = sampler.fit_sample(X_train, y_train)\n",
    "\n",
    "pd.Series(y_resampled).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7309644670050761\n",
      "0.6804487179487179\n",
      "0.7515384615384615\n",
      "\n",
      "[[135  62]\n",
      " [ 44 153]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72       197\n",
      "           1       0.71      0.78      0.74       197\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       394\n",
      "   macro avg       0.73      0.73      0.73       394\n",
      "weighted avg       0.73      0.73      0.73       394\n",
      "\n",
      "\n",
      "[[ 29  20]\n",
      " [303 948]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.59      0.15        49\n",
      "           1       0.98      0.76      0.85      1251\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      1300\n",
      "   macro avg       0.53      0.67      0.50      1300\n",
      "weighted avg       0.95      0.75      0.83      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fitter(model, X_resampled, y_resampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling can be used during gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7157360406091371\n",
      "0.6753205128205128\n",
      "0.75\n",
      "\n",
      "[[133  64]\n",
      " [ 48 149]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.68      0.70       197\n",
      "           1       0.70      0.76      0.73       197\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       394\n",
      "   macro avg       0.72      0.72      0.72       394\n",
      "weighted avg       0.72      0.72      0.72       394\n",
      "\n",
      "\n",
      "[[ 27  22]\n",
      " [303 948]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.55      0.14        49\n",
      "           1       0.98      0.76      0.85      1251\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      1300\n",
      "   macro avg       0.53      0.65      0.50      1300\n",
      "weighted avg       0.94      0.75      0.83      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=1000)\n",
    "\n",
    "model_params = {'penalty': ['l2'],\n",
    "                'C': np.logspace(-2, 2, 5)}\n",
    "\n",
    "gs = GridSearchCV(model, model_params, cv=5, iid=False)\n",
    "\n",
    "fitter(gs, X_resampled, y_resampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling\n",
    "\n",
    "We create class balance by sampling the minority class with replacement (bootstrapping).\n",
    "\n",
    "Be careful with the resampling and cross validation. **If you upsample before cross validation, you will have the same observations in different k-folds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    5000\n",
      "0    5000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sampler = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = sampler.fit_sample(X_train, y_train)\n",
    "\n",
    "print(pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7202\n",
      "0.7217\n",
      "0.7638461538461538\n",
      "\n",
      "[[3430 1570]\n",
      " [1228 3772]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71      5000\n",
      "           1       0.71      0.75      0.73      5000\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     10000\n",
      "   macro avg       0.72      0.72      0.72     10000\n",
      "weighted avg       0.72      0.72      0.72     10000\n",
      "\n",
      "\n",
      "[[ 29  20]\n",
      " [287 964]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.59      0.16        49\n",
      "           1       0.98      0.77      0.86      1251\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      1300\n",
      "   macro avg       0.54      0.68      0.51      1300\n",
      "weighted avg       0.95      0.76      0.84      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fitter(model, X_resampled, y_resampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to use cross validation, we have to set it up by hand and do the oversampling **after** we have created the k-folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7157360406091371\n",
      "0.6753205128205128\n",
      "0.75\n",
      "\n",
      "[[133  64]\n",
      " [ 48 149]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.68      0.70       197\n",
      "           1       0.70      0.76      0.73       197\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       394\n",
      "   macro avg       0.72      0.72      0.72       394\n",
      "weighted avg       0.72      0.72      0.72       394\n",
      "\n",
      "\n",
      "[[ 27  22]\n",
      " [303 948]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.55      0.14        49\n",
      "           1       0.98      0.76      0.85      1251\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      1300\n",
      "   macro avg       0.53      0.65      0.50      1300\n",
      "weighted avg       0.94      0.75      0.83      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"---------------------\"\"\"\n",
    "# wrong way\n",
    "\"\"\"---------------------\"\"\"\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=1000)\n",
    "\n",
    "model_params = {'penalty': ['l2'],\n",
    "                'C': np.logspace(-2, 2, 5)}\n",
    "\n",
    "gs = GridSearchCV(model, model_params, cv=5, iid=False)\n",
    "fitter(gs, X_resampled, y_resampled, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 \t 0.749 \t 0.768\n",
      "\n",
      "0.046 \t 0.75 \t 0.772\n",
      "\n",
      "0.215 \t 0.748 \t 0.778\n",
      "\n",
      "1.0 \t 0.747 \t 0.776\n",
      "\n",
      "4.642 \t 0.747 \t 0.777\n",
      "\n",
      "21.544 \t 0.747 \t 0.777\n",
      "\n",
      "100.0 \t 0.747 \t 0.777\n",
      "\n",
      "464.159 \t 0.747 \t 0.777\n",
      "\n",
      "2154.435 \t 0.747 \t 0.777\n",
      "\n",
      "10000.0 \t 0.747 \t 0.777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"---------------------\"\"\"\n",
    "# correct way\n",
    "\"\"\"---------------------\"\"\"\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for C_current in np.logspace(-2, 4, 10):\n",
    "    model = LogisticRegression(C=C_current, solver='lbfgs', multi_class='ovr', max_iter=1000)\n",
    "    \n",
    "    scores = []\n",
    "    for train, test in kf.split(X_train, y_train):\n",
    "        X_train_now, X_test_now = X_train.iloc[train, :], X_train.iloc[test, :]\n",
    "        y_train_now, y_test_now = y_train.iloc[train], y_train.iloc[test]\n",
    "\n",
    "        X_resampled, y_resampled = sampler.fit_sample(X_train_now, y_train_now)\n",
    "\n",
    "        model.fit(X_resampled, y_resampled)\n",
    "        scores.append(model.score(X_test_now, y_test_now))\n",
    "\n",
    "    print(np.round(C_current, 3), '\\t', \n",
    "          np.round(np.mean(scores), 3), '\\t', \n",
    "          np.round(model.score(X_test, y_test), 3))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a pipeline\n",
    "\n",
    "With imbalancedlearn's pipeline wrapper, we can use sampling without danger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751779873003656\n",
      "0.7471638779891908\n",
      "0.7638461538461538\n",
      "\n",
      "[[ 135   62]\n",
      " [1228 3772]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.69      0.17       197\n",
      "           1       0.98      0.75      0.85      5000\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5197\n",
      "   macro avg       0.54      0.72      0.51      5197\n",
      "weighted avg       0.95      0.75      0.83      5197\n",
      "\n",
      "\n",
      "[[ 29  20]\n",
      " [287 964]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.59      0.16        49\n",
      "           1       0.98      0.77      0.86      1251\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      1300\n",
      "   macro avg       0.54      0.68      0.51      1300\n",
      "weighted avg       0.95      0.76      0.84      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline_imb(RandomOverSampler(random_state=1),\n",
    "                         LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=1000))\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "predictions = pipe.predict(X_test)\n",
    "\n",
    "\n",
    "fitter(pipe, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two methods, SMOTE and ADASYN, create synthetic samples, i.e. new samples for restoring class balance, which were not contained in the original dataset. They are created by looking at  the k-nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5000\n",
       "0    5000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler = SMOTE(random_state=1)\n",
    "X_resampled, y_resampled = sampler.fit_sample(X_train, y_train)\n",
    "\n",
    "pd.Series(y_resampled).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7600538772368675\n",
      "0.7571685052195157\n",
      "0.7784615384615384\n",
      "\n",
      "[[ 134   63]\n",
      " [1184 3816]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.68      0.18       197\n",
      "           1       0.98      0.76      0.86      5000\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      5197\n",
      "   macro avg       0.54      0.72      0.52      5197\n",
      "weighted avg       0.95      0.76      0.83      5197\n",
      "\n",
      "\n",
      "[[ 30  19]\n",
      " [269 982]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.61      0.17        49\n",
      "           1       0.98      0.78      0.87      1251\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1300\n",
      "   macro avg       0.54      0.70      0.52      1300\n",
      "weighted avg       0.95      0.78      0.85      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline_imb(SMOTE(random_state=1),\n",
    "                         LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=1000))\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "predictions = pipe.predict(X_test)\n",
    "\n",
    "\n",
    "fitter(pipe, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling with ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5000\n",
       "0    4965\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler = ADASYN(random_state=1, n_neighbors=5)\n",
    "X_resampled, y_resampled = sampler.fit_sample(X_train, y_train)\n",
    "\n",
    "pd.Series(y_resampled).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7479314989416971\n",
      "0.7421594358480788\n",
      "0.7715384615384615\n",
      "\n",
      "[[ 138   59]\n",
      " [1251 3749]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.70      0.17       197\n",
      "           1       0.98      0.75      0.85      5000\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      5197\n",
      "   macro avg       0.54      0.73      0.51      5197\n",
      "weighted avg       0.95      0.75      0.83      5197\n",
      "\n",
      "\n",
      "[[ 29  20]\n",
      " [277 974]]\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.59      0.16        49\n",
      "           1       0.98      0.78      0.87      1251\n",
      "\n",
      "   micro avg       0.77      0.77      0.77      1300\n",
      "   macro avg       0.54      0.69      0.52      1300\n",
      "weighted avg       0.95      0.77      0.84      1300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline_imb(ADASYN(random_state=1, n_neighbors=5),\n",
    "                         LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=1000))\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "predictions = pipe.predict(X_test)\n",
    "\n",
    "\n",
    "fitter(pipe, X_train, y_train, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Lesson Guide",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
